# RAGbot Environment Configuration Template
# Rename this file to .env and fill in your specific values

# API Keys
# Required: Your OpenAI API key for generating responses
OPENAI_API_KEY=your_openai_api_key_here

# Database Configuration (used by both local Python and Docker)
POSTGRES_USER=myuser
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=vectordb
# Use 'postgres' when running within Docker network, 'localhost' for local development
DB_HOST=postgres
DB_PORT=5432
DB_USER=myuser
DB_PASSWORD=your_secure_password_here

# Vector DB Configuration
COLLECTION_NAME=document_chunks

# Model Configuration
# Embedding model to use for document vectorization
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Chunking Configuration
# Use either "fixed" or "semantic" chunking strategy
CHUNKING_STRATEGY=semantic

# Fixed-size chunking parameters (used if CHUNKING_STRATEGY=fixed)
# Size of text chunks for vectorization
CHUNK_SIZE=600
# Overlap between consecutive chunks
CHUNK_OVERLAP=100

# Semantic chunking parameters (used if CHUNKING_STRATEGY=semantic)
# Minimum size of chunks
MIN_CHUNK_SIZE=200
# Maximum size of chunks
MAX_CHUNK_SIZE=800
# Semantic similarity threshold (0.0-1.0) for determining chunk boundaries
SEMANTIC_SIMILARITY=0.6
# Whether to respect document structure like headings and lists (true/false)
RESPECT_STRUCTURE=true

# Processing Parameters
# Batch size for processing documents
BATCH_SIZE=500
# Number of parallel workers for document processing
MAX_WORKERS=8

# Data Location
# Directory containing documents to be indexed
DOCS_DIR=Documents

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Web UI Configuration (for OpenWebUI)
# Authentication token for the web interface
WEBUI_AUTH_TOKEN=your_secure_token_here
WEBUI_PORT=3000

# Optional: Llama CLI Configuration (only needed if using local Llama models)
# LLAMA_CLI_PATH=/path/to/llama/executable
# LLAMA_MODEL_PATH=/path/to/llama/model.gguf