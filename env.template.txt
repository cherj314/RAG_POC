# RAGbot Environment Configuration Template
# Rename this file to .env and fill in your specific values

# API Keys (only needed if using OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here

# Database Configuration (used by both local Python and Docker)
POSTGRES_USER=myuser
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=vectordb
# Use 'postgres' when running within Docker network, 'localhost' for local development
DB_HOST=postgres
DB_PORT=5432
DB_USER=myuser
DB_PASSWORD=your_secure_password_here

# Vector DB Configuration
COLLECTION_NAME=document_chunks

# Embedding Model Configuration
# Embedding model to use for document vectorization
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2

# LLM Configuration
# Default model type (openai or ollama)
DEFAULT_MODEL_TYPE=openai
# Available model types as comma-separated list, disable ollama to speed up development
AVAILABLE_MODEL_TYPES=openai,ollama
# Default OpenAI model
OPENAI_MODEL=gpt-4o
# Default 
OLLAMA_MODEL=llama3:instruct
# Temperature for generation (0.0-1.0)
TEMPERATURE=0.3
# Maximum tokens to generate
MAX_TOKENS=2048

# Ollama Configuration
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_PORT=11434

# LLM Configuration
# Choose between "openai" or "ollama" model types
MODEL_TYPE=openai
# Model name to use (for OpenAI: "gpt-4o", "gpt-3.5-turbo", or for ollama: "tinyllama")
MODEL_NAME=gpt-4o
# Temperature for generation (0.0-1.0)
TEMPERATURE=0.3
# Maximum tokens to generate
MAX_TOKENS=2048

# Ollama Configuration (only used if MODEL_TYPE=ollama)
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=tinyllama
OLLAMA_PORT=11434

# Chunking Configuration
# Use either "fixed" or "semantic" chunking strategy
CHUNKING_STRATEGY=semantic

# Fixed-size chunking parameters (used if CHUNKING_STRATEGY=fixed)
# Size of text chunks for vectorization
CHUNK_SIZE=600
# Overlap between consecutive chunks
CHUNK_OVERLAP=100

# Semantic chunking parameters (used if CHUNKING_STRATEGY=semantic)
# Minimum size of chunks
MIN_CHUNK_SIZE=200
# Maximum size of chunks
MAX_CHUNK_SIZE=800
# Semantic similarity threshold (0.0-1.0) for determining chunk boundaries
SEMANTIC_SIMILARITY=0.6
# Whether to respect document structure like headings and lists (true/false)
RESPECT_STRUCTURE=true

# Processing Parameters
# Batch size for processing documents
BATCH_SIZE=500
# Number of parallel workers for document processing
MAX_WORKERS=8

# Data Location
# Directory containing documents to be indexed
DOCS_DIR=Documents

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Web UI Configuration (for OpenWebUI)
# Authentication token for the web interface
WEBUI_AUTH_TOKEN=your_secure_token_here
WEBUI_PORT=3000