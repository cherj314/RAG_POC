# ğŸ§  RAGbot â€” Retrieval-Augmented Generation Assistant for Proposal Generation

RAGbot is a lightweight Retrieval-Augmented Generation (RAG) assistant designed to generate software proposals using historical scopes of work stored in a PostgreSQL vector database. It helps software companies quickly create customized proposals by retrieving relevant examples from past work.

## ğŸ“¦ Features

- ğŸ” **Context-Aware Retrieval**: Uses `pgvector` to search relevant past documents based on semantic similarity
- ğŸ§± **Modular Design**: Clean separation between retrieval, prompt construction, and generation
- ğŸ¤– **Generative AI Ready**: Works with OpenAI APIs and extendable to other LLMs
- ğŸ“Š **Flexible Similarity Thresholds**: Configure the relevance level of retrieved content
- ğŸŒ **Web Interface**: OpenWebUI integration for easy interaction

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Docker and Docker Compose
- OpenAI API key (for generation)

### One-Command Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/ragbot.git
cd ragbot

# Run setup script
python setup.py
```

The setup script will:
1. Check prerequisites
2. Create a `.env` file from `.env.example`
3. Set up a Python virtual environment
4. Install required dependencies
5. Create necessary directories

### Starting the System

```bash
# Start all services with Docker Compose
docker compose up -d

# Ingest your documents (only needed once or when documents change)
# Activate virtual environment first
source venv/bin/activate  # On Windows: venv\Scripts\activate
python ingest.py

# Run the interactive CLI (optional)
python main.py
```

### Accessing the Web Interface

Open your browser and navigate to:
```
http://localhost:3000
```

Use the default authentication token from your `.env` file to log in.

## ğŸ“‹ Usage Options

### Interactive CLI

```bash
python main.py
```

This starts the interactive command-line interface where you can directly input proposal requests.

### API Server

```bash
# Start the API server (if not using Docker)
python -m api
```

The API will be available at `http://localhost:8000`.

### Docker Deployment

All components (database, API, web UI) can be started with Docker Compose:

```bash
docker compose up -d
```

## ğŸ—„ï¸ Adding Your Own Documents

1. Place your text files in the `Documents/` folder
2. Run the ingestion script:
   ```bash
   python ingest.py
   ```

## ğŸ› ï¸ Architecture

RAGbot follows a simple but effective workflow:

1. **Retrieval**: Searches the vector database for relevant document chunks
2. **Prompt Building**: Constructs prompts that combine retrieved context with the user query
3. **Generation**: Passes the constructed prompt to an LLM to generate a coherent proposal

## âš™ï¸ Configuration

Edit `.env` file to customize:

- **OpenAI API Key**: Required for generation
- **Database Settings**: Connection details
- **Embedding Model**: Default is `sentence-transformers/all-MiniLM-L6-v2`
- **Chunking Parameters**: Size and overlap of document chunks
- **Server Ports**: API and Web UI ports

## ğŸ§© Project Structure

```
ragbot/
â”œâ”€â”€ .env.example           # Example environment variables
â”œâ”€â”€ .env                   # Your configured environment variables
â”œâ”€â”€ setup.py               # Setup script for easy installation
â”œâ”€â”€ api.py                 # FastAPI server for OpenWebUI integration
â”œâ”€â”€ main.py                # CLI entry point
â”œâ”€â”€ ingest.py              # Document ingestion script
â”œâ”€â”€ docker-compose.yml     # Docker Compose configuration
â”œâ”€â”€ Dockerfile             # PostgreSQL with pgvector
â”œâ”€â”€ Dockerfile-api         # API server container
â”œâ”€â”€ db-setup.sql           # Database initialization SQL
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ venv/                  # Python virtual environment
â”œâ”€â”€ Documents/             # Your document storage
â”‚   â””â”€â”€ project_proposals.txt  # Sample document
â””â”€â”€ rag/                   # Core RAG components
    â”œâ”€â”€ config.py          # Configuration and database connection
    â”œâ”€â”€ retriever.py       # Vector retrieval functionality
    â”œâ”€â”€ prompt_builder.py  # Prompt engineering
    â””â”€â”€ generator.py       # LLM integration
```

## ğŸ§ª Customization Options

### Using a Different LLM

To switch from OpenAI to another provider:

1. Modify the `generator.py` file to use your preferred API
2. Update the environment variables accordingly

### Embedding Model

You can change the embedding model in your `.env` file:

```
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
```

### Adding More Document Types

The system currently processes text files. To add support for PDFs, DOCs, etc.:

1. Install additional dependencies for document processing
2. Modify the `ingest.py` file to handle these file types

## ğŸ”’ Security Notes

- The `.env` file contains sensitive information including API keys
- Ensure it's added to `.gitignore` and not shared publicly
- For production deployment, use proper secrets management

## ğŸ“š Troubleshooting

### Common Issues

1. **Database Connection Errors**: 
   - Ensure PostgreSQL is running
   - Check your DB credentials in `.env`

2. **OpenAI API Errors**:
   - Verify your API key is correct
   - Check for sufficient API credits

3. **Ingestion Problems**:
   - Make sure the `Documents` directory exists
   - Check file permissions

For more detailed troubleshooting, check the API logs:
```bash
docker compose logs ragbot-api
```

## ğŸ™ Acknowledgments

- Built with [pgvector](https://github.com/pgvector/pgvector) for vector similarity search
- Uses [SentenceTransformers](https://www.sbert.net/) for embeddings
- Integration with [OpenWebUI](https://github.com/open-webui/open-webui)